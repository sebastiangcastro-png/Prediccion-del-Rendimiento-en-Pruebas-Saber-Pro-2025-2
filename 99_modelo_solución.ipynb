{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## üë• Autores\n",
        "\n",
        "Este proyecto fue desarrollado por:\n",
        "\n",
        "| Nombre Completo                     | N√∫mero de Identificaci√≥n | Carrera Universitaria              |\n",
        "| ----------------------------------- | -----------------------: | ---------------------------------- |\n",
        "| **Yorladys Argumedo Lozano**        | `1038824209`            | Ingenier√≠a Industrial Virtual      |\n",
        "| **Sebastian Gabriel Castro**        | `1029720632`            | Ingenier√≠a Industrial Virtual      |\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "dnxqlSf4nTde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# SOLUCI√ìN FINAL: ENSEMBLE DE POTENCIA PUNTAJE 0.43772\n",
        "# VERSI√ìN ADAPTADA PARA GOOGLE COLAB\n",
        "# ==============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "# Instalamos librer√≠as si no est√°n (por si acaso es un entorno nuevo)\n",
        "try:\n",
        "    import xgboost\n",
        "except ImportError:\n",
        "    !pip install xgboost lightgbm --quiet\n",
        "\n",
        "# Librer√≠as de Machine Learning Avanzado\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# Preprocesamiento\n",
        "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "\n",
        "# Configuraci√≥n\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. DETECCI√ìN DE ENTORNO Y CARGA DE DATOS (L√ìGICA COLAB)\n",
        "# ==============================================================================\n",
        "print(\"üìÇ Configurando entorno de datos...\")\n",
        "\n",
        "# Verificamos si los archivos YA existen localmente\n",
        "if os.path.exists('train.csv') and os.path.exists('test.csv'):\n",
        "    print(\"‚úÖ Archivos train.csv y test.csv detectados localmente.\")\n",
        "    print(\"   -> Omitiendo descarga de Kaggle para ahorrar tiempo.\")\n",
        "    base_path = '.'\n",
        "\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Archivos no encontrados. Se proceder√° a descargarlos desde Kaggle.\")\n",
        "\n",
        "    # Verificamos si tenemos el json, si no, lo pedimos\n",
        "    if not os.path.exists('kaggle.json'):\n",
        "        print(\"Por favor, sube el archivo 'kaggle.json' ahora:\")\n",
        "        from google.colab import files\n",
        "        uploaded = files.upload()\n",
        "\n",
        "    print(\"Configurando API de Kaggle...\")\n",
        "    # Comandos de configuraci√≥n\n",
        "    !mkdir -p ~/.kaggle\n",
        "    !cp kaggle.json ~/.kaggle/\n",
        "    !chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "    print(\"Descargando dataset...\")\n",
        "    # Descarga espec√≠fica de la competencia\n",
        "    !kaggle competitions download -c udea-ai-4-eng-20252-pruebas-saber-pro-colombia\n",
        "\n",
        "    print(\"Descomprimiendo...\")\n",
        "    !unzip -q -o udea-ai-4-eng-20252-pruebas-saber-pro-colombia.zip\n",
        "    print(\"¬°Descarga y descompresi√≥n completada!\")\n",
        "    base_path = '.'\n",
        "\n",
        "# Cargar datos\n",
        "print(f\"\\nLeyendo CSVs desde: {base_path}\")\n",
        "df_train = pd.read_csv(os.path.join(base_path, 'train.csv'))\n",
        "df_test = pd.read_csv(os.path.join(base_path, 'test.csv'))\n",
        "test_ids = df_test['ID']\n",
        "\n",
        "print(f\"Train shape: {df_train.shape}\")\n",
        "print(f\"Test shape: {df_test.shape}\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. INGENIER√çA DE CARACTER√çSTICAS (FEATURE ENGINEERING)\n",
        "# ==============================================================================\n",
        "def enrich_data(df):\n",
        "    df_eng = df.copy()\n",
        "\n",
        "    # 1. Conteo de Nulos\n",
        "    df_eng['NUM_NULOS'] = df_eng.isnull().sum(axis=1)\n",
        "\n",
        "    # 2. √çndice de Riqueza Tecnol√≥gica\n",
        "    cols_tiene = [c for c in df.columns if 'TIENE' in c.upper()]\n",
        "    df_eng['INDICE_RIQUEZA'] = 0\n",
        "    for col in cols_tiene:\n",
        "        # Convertimos Si/No a 1/0\n",
        "        mapper = {'Si': 1, 'No': 0, 'S√ç': 1, 'NO': 0, 'si': 1, 'no': 0}\n",
        "        df_eng[col] = df_eng[col].map(mapper)\n",
        "        df_eng['INDICE_RIQUEZA'] += df_eng[col].fillna(0)\n",
        "\n",
        "    return df_eng\n",
        "\n",
        "print(\"üõ†Ô∏è Aplicando ingenier√≠a de caracter√≠sticas...\")\n",
        "df_train = enrich_data(df_train)\n",
        "df_test = enrich_data(df_test)\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. PREPARACI√ìN DE PIPELINES\n",
        "# ==============================================================================\n",
        "target_col = 'RENDIMIENTO_GLOBAL'\n",
        "label_map = {'bajo': 0, 'medio-bajo': 1, 'medio-alto': 2, 'alto': 3}\n",
        "inverse_map = {0: 'bajo', 1: 'medio-bajo', 2: 'medio-alto', 3: 'alto'}\n",
        "\n",
        "X = df_train.drop(columns=[target_col, 'ID'], errors='ignore')\n",
        "y = df_train[target_col].map(label_map)\n",
        "X_kaggle = df_test.drop(columns=['ID'], errors='ignore')\n",
        "\n",
        "# Identificar columnas\n",
        "num_cols = X.select_dtypes(include=['number']).columns.tolist()\n",
        "cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "\n",
        "# Pipeline Num√©rico\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Pipeline Categ√≥rico\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='MISSING')),\n",
        "    ('ordinal', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, num_cols),\n",
        "        ('cat', categorical_transformer, cat_cols)\n",
        "    ],\n",
        "    verbose_feature_names_out=False\n",
        ")\n",
        "\n",
        "# ==============================================================================\n",
        "# 4. DEFINICI√ìN DE MODELOS \"STATE OF THE ART\"\n",
        "# ==============================================================================\n",
        "\n",
        "# MODELO 1: XGBoost\n",
        "xgb_params = {\n",
        "    'n_estimators': 800,\n",
        "    'learning_rate': 0.02,\n",
        "    'max_depth': 8,\n",
        "    'subsample': 0.7,\n",
        "    'colsample_bytree': 0.7,\n",
        "    'objective': 'multi:softprob',\n",
        "    'random_state': 42,\n",
        "    'n_jobs': -1,\n",
        "    'tree_method': 'hist'\n",
        "}\n",
        "\n",
        "# MODELO 2: LightGBM\n",
        "lgbm_params = {\n",
        "    'n_estimators': 1000,\n",
        "    'learning_rate': 0.03,\n",
        "    'num_leaves': 40,\n",
        "    'max_depth': -1,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.8,\n",
        "    'objective': 'multiclass',\n",
        "    'random_state': 123,\n",
        "    'n_jobs': -1,\n",
        "    'verbose': -1\n",
        "}\n",
        "\n",
        "# Creamos los pipelines individuales\n",
        "pipe_xgb = Pipeline([('pre', preprocessor), ('clf', XGBClassifier(**xgb_params))])\n",
        "pipe_lgbm = Pipeline([('pre', preprocessor), ('clf', LGBMClassifier(**lgbm_params))])\n",
        "\n",
        "# ==============================================================================\n",
        "# 5. ENSAMBLAJE (VOTING CLASSIFIER)\n",
        "# ==============================================================================\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('xgb', pipe_xgb),\n",
        "        ('lgbm', pipe_lgbm)\n",
        "    ],\n",
        "    voting='soft',\n",
        "    weights=[1, 1]\n",
        ")\n",
        "\n",
        "# ==============================================================================\n",
        "# 6. ENTRENAMIENTO Y GENERACI√ìN DE ARCHIVO\n",
        "# ==============================================================================\n",
        "print(\"üèãÔ∏è Iniciando entrenamiento del Ensemble (XGBoost + LightGBM)...\")\n",
        "print(\"   (Esto puede tomar unos minutos en Colab)...\")\n",
        "\n",
        "voting_clf.fit(X, y)\n",
        "print(\"‚úÖ Entrenamiento completado.\")\n",
        "\n",
        "print(\"üîÆ Generando predicciones...\")\n",
        "y_pred_indices = voting_clf.predict(X_kaggle)\n",
        "\n",
        "# Convertir n√∫meros a texto\n",
        "y_pred_text = [inverse_map[v] for v in y_pred_indices]\n",
        "\n",
        "# Crear DataFrame\n",
        "submission = pd.DataFrame({\n",
        "    'ID': test_ids,\n",
        "    'RENDIMIENTO_GLOBAL': y_pred_text\n",
        "})\n",
        "\n",
        "# Guardar\n",
        "filename = 'submission_colab_ensemble.csv'\n",
        "submission.to_csv(filename, index=False)\n",
        "\n",
        "print(f\"\\nüèÜ ¬°Archivo '{filename}' generado!\")\n",
        "print(f\"Dimensiones: {submission.shape}\")\n",
        "# C√≥digo para descargar autom√°ticamente en Colab (opcional)\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(filename)\n",
        "except:\n",
        "    print(\"Descarga el archivo manualmente desde la carpeta de archivos.\")"
      ],
      "metadata": {
        "id": "7ijFRI5w_ejW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}