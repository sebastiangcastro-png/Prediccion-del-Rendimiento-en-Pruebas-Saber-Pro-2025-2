# Proyecto: Predicci贸n del Rendimiento en Pruebas Saber Pro 

Este repositorio contiene el desarrollo de un modelo de Machine Learning para predecir el rendimiento de los estudiantes en las pruebas Saber Pro, bas谩ndose en datos socioecon贸micos y acad茅micos.

##  Autores

Este proyecto fue desarrollado por:

| Nombre Completo | N煤mero de Identificaci贸n | Carrera Universitaria |
| :--- | :--- | :--- |
| **Yorladys Argumedo Lozano** | `1038824209` | Ingenier铆a Industrial Virtual |
| **Sebastian Gabriel Castro** | `1029720632` | Ingenier铆a Industrial Virtual |

##  Entregas y Videos

A continuaci贸n se presentan los enlaces a las sustentaciones de las entregas del curso:

*   **Entrega 2 (Preprocesado):** [Ver en YouTube](https://youtu.be/771uPZHF0mw)
*   **Entrega 3 (Final - Soluci贸n Kaggle):** [VIDEO FINAL DE YOUTUB](https://youtu.be/yFXWDBA53HQ)

---

##  Descripci贸n del Proyecto

El objetivo principal es construir un modelo de clasificaci贸n capaz de asignar a cada estudiante una de las cuatro categor铆as de rendimiento definidas (**Bajo, Medio-Bajo, Medio-Alto, Alto**). Para lograrlo, se realiza un proceso completo que abarca desde la exploraci贸n y limpieza de los datos hasta el entrenamiento y la evaluaci贸n de diferentes algoritmos de Machine Learning.

Este proyecto se desarrolla en el marco de la competencia de Kaggle para el curso de **Introducci贸n a la Inteligencia Artificial**.

##  Aproximaci贸n a la Soluci贸n Final (Notebook 99)

Para la soluci贸n definitiva enviada a Kaggle, implementamos un pipeline robusto que incluye:

1.  **Preprocesamiento:**
    *   Imputaci贸n de valores num茅ricos usando la mediana.
    *   Imputaci贸n de valores categ贸ricos faltantes con una constante.
    *   Codificaci贸n de variables categ贸ricas mediante **One-Hot Encoding**.
    *   Escalado de variables num茅ricas con **StandardScaler**.
2.  **Modelo Seleccionado:**
    *   Se utiliz贸 un **Random Forest Classifier**. Este modelo fue seleccionado por su capacidad para manejar relaciones no lineales y su robustez frente al sobreajuste (overfitting) en comparaci贸n con otros modelos probados.
3.  **Resultados:**
    *   Esta estrategia nos permiti贸 generar el archivo `submission.csv` respetando los IDs del conjunto de test de la competencia.

##  Estructura del Repositorio

El proyecto est谩 organizado siguiendo estrictamente los requisitos de la entrega:

*   **`README.md`**: Informaci贸n general, autores y enlaces a videos.
*   **`01 - exploraci贸n.ipynb`**: (Entrega 1) Carga de datos (`train.csv`, `test.csv`) y An谩lisis Exploratorio de Datos (EDA).
*   **`02 - preprocesado.ipynb`**: (Entrega 2) Limpieza, manejo de nulos e ingenier铆a de caracter铆sticas inicial.
*   **`03 - modelo con SVM.ipynb`**: Notebook experimental donde se prueba una aproximaci贸n usando *Support Vector Machines*.
*   **`04 - modelo con KNN.ipynb`**: Notebook experimental utilizando el algoritmo de *K-Nearest Neighbors*.
*   **`99 - modelo soluci贸n.ipynb`**: **(Entrega Final)** Notebook autocontenido que ejecuta el pipeline completo: carga datos, preprocesa, entrena el modelo Random Forest y genera el archivo `submission.csv` para Kaggle.

##  Tecnolog铆as Utilizadas

Para el desarrollo de este proyecto se utilizaron las siguientes herramientas y librer铆as de Python:

*   **Python 3.x**
*   **Pandas:** Manipulaci贸n y an谩lisis de datos tabulares.
*   **NumPy:** Operaciones num茅ricas eficientes.
*   **Scikit-learn:** Entrenamiento de modelos, pipelines y preprocesamiento.
*   **Matplotlib y Seaborn:** Visualizaci贸n de datos.
*   **Kaggle API:** Para la descarga automatizada del dataset.
*   **Google Colab:** Entorno de desarrollo.

---


